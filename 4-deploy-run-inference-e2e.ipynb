{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 : Deploy, Run Inference, Interpret Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='overview-4'></a>\n",
    "\n",
    "## [Overview](./0-AutoClaimFraudDetection.ipynb)\n",
    "* [Notebook 0 : Overview, Architecture and Data Exploration](./0-AutoClaimFraudDetection.ipynb)\n",
    "* [Notebook 1: Data Prep, Process, Store Features](./1-data-prep-e2e.ipynb)\n",
    "* [Notebook 2: Train, Check Bias, Tune, Record Lineage, and Register a Model](./2-lineage-train-assess-bias-tune-registry-e2e.ipynb)\n",
    "* [Notebook 3: Mitigate Bias, Train New Model, Store in Registry](./3-mitigate-bias-train-model2-registry-e2e.ipynb)\n",
    "* **[Notebook 4: Deploy Model, Run Predictions](./4-deploy-run-inference-e2e.ipynb)**\n",
    "  * **[Architecture](#deploy)**\n",
    "  * **[Deploy an approved model and Run Inference via Feature Store](#deploy-model)**\n",
    "  * **[Create a Predictor](#predictor)**\n",
    "  * **[Run Predictions from Online FeatureStore](#run-predictions)**\n",
    "* [Notebook 5 : Create and Run an End-to-End Pipeline to Deploy the Model](./5-pipeline-e2e.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End-to-end 유즈케이스를 다루는 이 섹션에서는, 사기 탐지 사용 사례의 최종 프로덕션인 mmitigated 모델을 배포합니다. 추론을 실행하는 방법과 Clarify를 사용하여 모델을 해석하거나 \"설명\"하는 방법을 보여줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required and/or update third-party libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Error parsing requirements for slicer: [Errno 2] No such file or directory: '/opt/conda/lib/python3.7/site-packages/slicer-0.0.7.dist-info/METADATA'\u001b[0m\n",
      "\u001b[33mWARNING: Error parsing requirements for slicer: [Errno 2] No such file or directory: '/opt/conda/lib/python3.7/site-packages/slicer-0.0.7.dist-info/METADATA'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install -Uq pip\n",
    "!python -m pip install -q awswrangler==2.2.0 imbalanced-learn==0.7.0 sagemaker==2.23.1 boto3==1.16.48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load stored variables\n",
    "\n",
    "이전에 이 노트북을 실행한 경우, AWS에서 생성한 리소스를 재사용할 수 있습니다. 아래 셀을 실행하여 이전에 생성된 변수를 로드합니다. 기존 변수의 출력물이 표시되어야 합니다. 인쇄된 내용이 보이지 않으면 노트북을 처음 실행한 것일 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "bucket                              -> 'sagemaker-us-east-1-870180618679'\n",
      "claims_fg_name                      -> 'fraud-detect-demo-claims'\n",
      "claims_table                        -> 'fraud-detect-demo-claims-1618149822'\n",
      "clarify_bias_job_1_name             -> 'Clarify-Bias-2021-04-12-14-04-59-864'\n",
      "clarify_bias_job_2_name             -> 'Clarify-Bias-2021-04-11-15-19-23-754'\n",
      "clarify_expl_job_name               -> 'Clarify-Explainability-2021-04-12-13-11-43-108'\n",
      "col_order                           -> ['fraud', 'total_claim_amount', 'police_report_ava\n",
      "customers_fg_name                   -> 'fraud-detect-demo-customers'\n",
      "customers_table                     -> 'fraud-detect-demo-customers-1618149825'\n",
      "database_name                       -> 'sagemaker_featurestore'\n",
      "hyperparameters                     -> {'max_depth': '3', 'eta': '0.2', 'objective': 'bin\n",
      "model_1_name                        -> 'fraud-detect-demo-xgboost-pre-smote'\n",
      "model_2_name                        -> 'fraud-detect-demo-xgboost-post-smote'\n",
      "mp2_arn                             -> 'arn:aws:sagemaker:us-east-1:870180618679:model-pa\n",
      "mpg_name                            -> 'fraud-detect-demo'\n",
      "prefix                              -> 'fraud-detect-demo'\n",
      "test_data_uri                       -> 's3://sagemaker-us-east-1-870180618679/fraud-detec\n",
      "train_data_uri                      -> 's3://sagemaker-us-east-1-870180618679/fraud-detec\n",
      "training_job_1_name                 -> 'sagemaker-xgboost-2021-04-11-14-15-09-012'\n",
      "training_job_2_name                 -> 'sagemaker-xgboost-2021-04-11-15-05-06-441'\n"
     ]
    }
   ],
   "source": [
    "%store -r\n",
    "%store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Important</font>: StoreMagic 명령을 사용하여 변수를 검색하려면 이전 노트북을 실행해야 합니다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import boto3\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import awswrangler as wr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set region, boto3 and SageMaker SDK variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using AWS Region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "#You can change this to a region of your choice\n",
    "import sagemaker\n",
    "region = sagemaker.Session().boto_region_name\n",
    "print(\"Using AWS Region: {}\".format(region))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.setup_default_session(region_name=region)\n",
    "\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "s3_client = boto3.client('s3', region_name=region)\n",
    "\n",
    "sagemaker_boto_client = boto_session.client('sagemaker')\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_boto_client)\n",
    "\n",
    "sagemaker_role = sagemaker.get_execution_role()\n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity()[\"Account\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables used for parameterizing the notebook run\n",
    "endpoint_name = f'{model_2_name}-endpoint'\n",
    "endpoint_instance_count = 1\n",
    "endpoint_instance_type = \"ml.m4.xlarge\"\n",
    "\n",
    "predictor_instance_count = 1\n",
    "predictor_instance_type = \"ml.c5.xlarge\"\n",
    "batch_transform_instance_count = 1\n",
    "batch_transform_instance_type = \"ml.c5.xlarge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id ='deploy'> </a>\n",
    "## Architecture for this ML Lifecycle Stage : Train, Check Bias, Tune, Record Lineage, Register Model\n",
    "[overview](#overview-4)\n",
    "\n",
    "![train-assess-tune-register](./images/e2e-3-pipeline-v3b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id ='deploy-model'></a>\n",
    "\n",
    "## Deploy an approved model and make prediction via Feature Store\n",
    "\n",
    "[overview](#overview-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approve the second model\n",
    "\n",
    "실제 MLOps 라이프사이클에서 모델 패키지는 데이터 과학자, 주제 전문가 및 감사자가 평가한 후 승인됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_model_package = sagemaker_boto_client.list_model_packages(ModelPackageGroupName=mpg_name)['ModelPackageSummaryList'][0]\n",
    "model_package_update = {\n",
    "    'ModelPackageArn': second_model_package['ModelPackageArn'],\n",
    "    'ModelApprovalStatus': 'Approved'\n",
    "}\n",
    "\n",
    "update_response = sagemaker_boto_client.update_model_package(**model_package_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an endpoint config and an endpoint\n",
    "엔드포인트를 배포합니다. 약 8분 정도 걸릴 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_container = {'ModelPackageName': second_model_package['ModelPackageArn']}\n",
    "endpoint_config_name=f'{model_2_name}-endpoint-config'\n",
    "existing_configs = len(sagemaker_boto_client.list_endpoint_configs(NameContains=endpoint_config_name, MaxResults = 30)['EndpointConfigs'])\n",
    "\n",
    "if existing_configs == 0:\n",
    "    create_ep_config_response = sagemaker_boto_client.create_endpoint_config(\n",
    "        EndpointConfigName=endpoint_config_name,\n",
    "        ProductionVariants=[{\n",
    "            'InstanceType': endpoint_instance_type,\n",
    "            'InitialVariantWeight': 1,\n",
    "            'InitialInstanceCount': endpoint_instance_count,\n",
    "            'ModelName': model_2_name,\n",
    "            'VariantName': 'AllTraffic'\n",
    "        }]\n",
    "    )\n",
    "    %store endpoint_config_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'endpoint_name' (str)\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: InService\n"
     ]
    }
   ],
   "source": [
    "existing_endpoints = sagemaker_boto_client.list_endpoints(NameContains=endpoint_name, MaxResults = 30)['Endpoints']\n",
    "if not existing_endpoints:\n",
    "    create_endpoint_response = sagemaker_boto_client.create_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        EndpointConfigName=endpoint_config_name)\n",
    "    %store endpoint_name\n",
    "\n",
    "endpoint_info = sagemaker_boto_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "endpoint_status = endpoint_info['EndpointStatus']\n",
    "\n",
    "while endpoint_status == 'Creating':\n",
    "    endpoint_info = sagemaker_boto_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    endpoint_status = endpoint_info['EndpointStatus']\n",
    "    print('Endpoint status:', endpoint_status)\n",
    "    if endpoint_status == 'Creating':\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='predictor'> </a>\n",
    "\n",
    "### Create a predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = sagemaker.predictor.Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample a claim from the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/dataset.csv')\n",
    "train = dataset.sample(frac=0.8, random_state=0)\n",
    "test = dataset.drop(train.index)\n",
    "sample_policy_id  = int(test.sample(1)['policy_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 0 to 4997\n",
      "Data columns (total 47 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   policy_id                        1000 non-null   int64  \n",
      " 1   total_claim_amount               1000 non-null   float64\n",
      " 2   police_report_available          1000 non-null   int64  \n",
      " 3   num_insurers_past_5_years        1000 non-null   int64  \n",
      " 4   customer_gender_male             1000 non-null   int64  \n",
      " 5   collision_type_na                1000 non-null   int64  \n",
      " 6   incident_day                     1000 non-null   int64  \n",
      " 7   incident_hour                    1000 non-null   int64  \n",
      " 8   incident_month                   1000 non-null   int64  \n",
      " 9   driver_relationship_child        1000 non-null   int64  \n",
      " 10  authorities_contacted_none       1000 non-null   int64  \n",
      " 11  driver_relationship_other        1000 non-null   int64  \n",
      " 12  authorities_contacted_fire       1000 non-null   int64  \n",
      " 13  customer_gender_female           1000 non-null   int64  \n",
      " 14  policy_state_wa                  1000 non-null   int64  \n",
      " 15  num_injuries                     1000 non-null   int64  \n",
      " 16  months_as_customer               1000 non-null   int64  \n",
      " 17  driver_relationship_na           1000 non-null   int64  \n",
      " 18  authorities_contacted_ambulance  1000 non-null   int64  \n",
      " 19  num_claims_past_year             1000 non-null   int64  \n",
      " 20  incident_type_collision          1000 non-null   int64  \n",
      " 21  incident_dow                     1000 non-null   int64  \n",
      " 22  injury_claim                     1000 non-null   float64\n",
      " 23  collision_type_side              1000 non-null   int64  \n",
      " 24  policy_state_id                  1000 non-null   int64  \n",
      " 25  auto_year                        1000 non-null   int64  \n",
      " 26  vehicle_claim                    1000 non-null   float64\n",
      " 27  policy_annual_premium            1000 non-null   int64  \n",
      " 28  policy_state_or                  1000 non-null   int64  \n",
      " 29  customer_education               1000 non-null   int64  \n",
      " 30  incident_severity                1000 non-null   int64  \n",
      " 31  policy_state_ca                  1000 non-null   int64  \n",
      " 32  driver_relationship_self         1000 non-null   int64  \n",
      " 33  policy_state_az                  1000 non-null   int64  \n",
      " 34  policy_deductable                1000 non-null   int64  \n",
      " 35  num_vehicles_involved            1000 non-null   int64  \n",
      " 36  driver_relationship_spouse       1000 non-null   int64  \n",
      " 37  incident_type_theft              1000 non-null   int64  \n",
      " 38  customer_age                     1000 non-null   int64  \n",
      " 39  policy_liability                 1000 non-null   int64  \n",
      " 40  collision_type_front             1000 non-null   int64  \n",
      " 41  fraud                            1000 non-null   int64  \n",
      " 42  authorities_contacted_police     1000 non-null   int64  \n",
      " 43  policy_state_nv                  1000 non-null   int64  \n",
      " 44  num_witnesses                    1000 non-null   int64  \n",
      " 45  incident_type_breakin            1000 non-null   int64  \n",
      " 46  collision_type_rear              1000 non-null   int64  \n",
      "dtypes: float64(3), int64(44)\n",
      "memory usage: 375.0 KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get sample's claim data from online feature store\n",
    "\n",
    "아래 코드 셀은 고객의 보험 청구 제출에서 실시간으로 데이터를 가져 오는 것을 시뮬레이션합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurestore_runtime = boto_session.client(service_name='sagemaker-featurestore-runtime', region_name=region)\n",
    "\n",
    "feature_store_session = sagemaker.Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_boto_client,\n",
    "    sagemaker_featurestore_runtime_client=featurestore_runtime\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='run-predictions'> </a>\n",
    "## Run Predictions on Multiple Claims\n",
    "\n",
    "[overview](#overview-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probablitity the claim from policy 1110 is fraudulent: 0.2992566227912903\n",
      "Probablitity the claim from policy 3661 is fraudulent: 0.3037422001361847\n",
      "Probablitity the claim from policy 3650 is fraudulent: 0.3256562352180481\n",
      "Probablitity the claim from policy 716 is fraudulent: 0.2992566227912903\n",
      "Probablitity the claim from policy 2875 is fraudulent: 0.27160611748695374\n",
      "Probablitity the claim from policy 3435 is fraudulent: 0.31473246216773987\n",
      "Probablitity the claim from policy 4557 is fraudulent: 0.3415466547012329\n",
      "Probablitity the claim from policy 1565 is fraudulent: 0.27160611748695374\n",
      "Probablitity the claim from policy 762 is fraudulent: 0.3256562352180481\n",
      "Probablitity the claim from policy 547 is fraudulent: 0.2718566060066223\n",
      "Probablitity the claim from policy 3942 is fraudulent: 0.27160611748695374\n",
      "Probablitity the claim from policy 3205 is fraudulent: 0.2992566227912903\n",
      "Probablitity the claim from policy 2800 is fraudulent: 0.3256562352180481\n",
      "Probablitity the claim from policy 2987 is fraudulent: 0.31473246216773987\n",
      "Probablitity the claim from policy 1362 is fraudulent: 0.27160611748695374\n",
      "Probablitity the claim from policy 85 is fraudulent: 0.3037422001361847\n",
      "Probablitity the claim from policy 822 is fraudulent: 0.27160611748695374\n",
      "Probablitity the claim from policy 2706 is fraudulent: 0.2992566227912903\n",
      "Probablitity the claim from policy 1377 is fraudulent: 0.2819044589996338\n",
      "Probablitity the claim from policy 4821 is fraudulent: 0.31445956230163574\n",
      "Probablitity the claim from policy 748 is fraudulent: 0.26179155707359314\n",
      "Probablitity the claim from policy 3656 is fraudulent: 0.26179155707359314\n",
      "Probablitity the claim from policy 559 is fraudulent: 0.24821297824382782\n",
      "Probablitity the claim from policy 4281 is fraudulent: 0.26179155707359314\n",
      "Probablitity the claim from policy 4918 is fraudulent: 0.27160611748695374\n",
      "Probablitity the claim from policy 3578 is fraudulent: 0.31473246216773987\n",
      "Probablitity the claim from policy 865 is fraudulent: 0.3256562352180481\n",
      "Probablitity the claim from policy 1050 is fraudulent: 0.27160611748695374\n",
      "Probablitity the claim from policy 3521 is fraudulent: 0.3415466547012329\n",
      "Probablitity the claim from policy 3598 is fraudulent: 0.31445956230163574\n",
      "Probablitity the claim from policy 4498 is fraudulent: 0.2965989410877228\n",
      "Probablitity the claim from policy 1852 is fraudulent: 0.28883910179138184\n",
      "Probablitity the claim from policy 23 is fraudulent: 0.26179155707359314\n",
      "Probablitity the claim from policy 3631 is fraudulent: 0.31445956230163574\n",
      "Probablitity the claim from policy 1994 is fraudulent: 0.31445956230163574\n",
      "Probablitity the claim from policy 1629 is fraudulent: 0.27160611748695374\n",
      "Probablitity the claim from policy 2651 is fraudulent: 0.31445956230163574\n",
      "Probablitity the claim from policy 1979 is fraudulent: 0.28883910179138184\n",
      "Probablitity the claim from policy 3026 is fraudulent: 0.31445956230163574\n",
      "Probablitity the claim from policy 4511 is fraudulent: 0.27160611748695374\n",
      "Probablitity the claim from policy 2414 is fraudulent: 0.3256562352180481\n",
      "Probablitity the claim from policy 91 is fraudulent: 0.27160611748695374\n",
      "Probablitity the claim from policy 2269 is fraudulent: 0.31445956230163574\n",
      "Probablitity the claim from policy 2515 is fraudulent: 0.28883910179138184\n",
      "Probablitity the claim from policy 3049 is fraudulent: 0.2819044589996338\n",
      "Probablitity the claim from policy 4067 is fraudulent: 0.2576962113380432\n",
      "Probablitity the claim from policy 2519 is fraudulent: 0.2819044589996338\n",
      "Probablitity the claim from policy 2042 is fraudulent: 0.24821297824382782\n",
      "Probablitity the claim from policy 4629 is fraudulent: 0.2992566227912903\n",
      "Probablitity the claim from policy 1236 is fraudulent: 0.31445956230163574\n",
      "Probablitity the claim from policy 4137 is fraudulent: 0.26179155707359314\n",
      "Probablitity the claim from policy 3329 is fraudulent: 0.31473246216773987\n",
      "Probablitity the claim from policy 1805 is fraudulent: 0.31445956230163574\n",
      "Probablitity the claim from policy 4752 is fraudulent: 0.31445956230163574\n",
      "Probablitity the claim from policy 3747 is fraudulent: 0.28883910179138184\n",
      "Probablitity the claim from policy 4938 is fraudulent: 0.2576962113380432\n",
      "Probablitity the claim from policy 2550 is fraudulent: 0.3037422001361847\n",
      "Probablitity the claim from policy 2618 is fraudulent: 0.28883910179138184\n",
      "Probablitity the claim from policy 769 is fraudulent: 0.27160611748695374\n",
      "Probablitity the claim from policy 3050 is fraudulent: 0.27160611748695374\n",
      "Probablitity the claim from policy 2351 is fraudulent: 0.31445956230163574\n",
      "Probablitity the claim from policy 1100 is fraudulent: 0.27160611748695374\n",
      "Probablitity the claim from policy 3190 is fraudulent: 0.3256562352180481\n",
      "Probablitity the claim from policy 1196 is fraudulent: 0.2965989410877228\n",
      "Probablitity the claim from policy 3547 is fraudulent: 0.28883910179138184\n",
      "Probablitity the claim from policy 3148 is fraudulent: 0.28883910179138184\n",
      "Probablitity the claim from policy 2198 is fraudulent: 0.24821297824382782\n",
      "Probablitity the claim from policy 2276 is fraudulent: 0.26179155707359314\n",
      "Probablitity the claim from policy 2590 is fraudulent: 0.3256562352180481\n",
      "Probablitity the claim from policy 3239 is fraudulent: 0.26179155707359314\n",
      "Probablitity the claim from policy 4596 is fraudulent: 0.31445956230163574\n",
      "Probablitity the claim from policy 3470 is fraudulent: 0.27160611748695374\n",
      "Probablitity the claim from policy 1344 is fraudulent: 0.2992566227912903\n",
      "Probablitity the claim from policy 4553 is fraudulent: 0.3037422001361847\n",
      "Probablitity the claim from policy 4776 is fraudulent: 0.2965989410877228\n",
      "Probablitity the claim from policy 3826 is fraudulent: 0.3037422001361847\n",
      "Probablitity the claim from policy 3858 is fraudulent: 0.3256562352180481\n",
      "Probablitity the claim from policy 2339 is fraudulent: 0.2576962113380432\n",
      "Probablitity the claim from policy 2800 is fraudulent: 0.3256562352180481\n",
      "Probablitity the claim from policy 339 is fraudulent: 0.28623613715171814\n",
      "Probablitity the claim from policy 3034 is fraudulent: 0.31473246216773987\n",
      "Probablitity the claim from policy 2928 is fraudulent: 0.27160611748695374\n",
      "Probablitity the claim from policy 3161 is fraudulent: 0.27160611748695374\n",
      "Probablitity the claim from policy 1384 is fraudulent: 0.3256562352180481\n",
      "Probablitity the claim from policy 2389 is fraudulent: 0.27160611748695374\n",
      "Probablitity the claim from policy 3577 is fraudulent: 0.31473246216773987\n",
      "Probablitity the claim from policy 644 is fraudulent: 0.28883910179138184\n",
      "Probablitity the claim from policy 847 is fraudulent: 0.27160611748695374\n",
      "Probablitity the claim from policy 2961 is fraudulent: 0.27160611748695374\n",
      "Probablitity the claim from policy 3108 is fraudulent: 0.31473246216773987\n",
      "Probablitity the claim from policy 3293 is fraudulent: 0.28623613715171814\n",
      "Probablitity the claim from policy 3040 is fraudulent: 0.24821297824382782\n",
      "Probablitity the claim from policy 1160 is fraudulent: 0.27160611748695374\n",
      "Probablitity the claim from policy 1181 is fraudulent: 0.27160611748695374\n",
      "Probablitity the claim from policy 1205 is fraudulent: 0.31445956230163574\n",
      "Probablitity the claim from policy 3866 is fraudulent: 0.40449997782707214\n",
      "Probablitity the claim from policy 3389 is fraudulent: 0.33035096526145935\n",
      "Probablitity the claim from policy 1224 is fraudulent: 0.27160611748695374\n",
      "Probablitity the claim from policy 2199 is fraudulent: 0.31445956230163574\n",
      "Probablitity the claim from policy 3602 is fraudulent: 0.3037422001361847\n"
     ]
    }
   ],
   "source": [
    "import datetime  as datetime\n",
    "timer =[]\n",
    "MAXRECS = 100\n",
    "\n",
    "def barrage_of_inference():\n",
    "    sample_policy_id  = int(test.sample(1)['policy_id'])\n",
    "    \n",
    "    temp_fg_name = 'fraud-detect-demo-claims'\n",
    "\n",
    "    claims_response = featurestore_runtime.get_record(\n",
    "        FeatureGroupName=temp_fg_name, \n",
    "        RecordIdentifierValueAsString= str(sample_policy_id)\n",
    "\n",
    "    )\n",
    "\n",
    "    if (claims_response.get('Record')):\n",
    "        claims_record = claims_response['Record']\n",
    "        claims_df = pd.DataFrame(claims_record).set_index('FeatureName')\n",
    "    else:\n",
    "        print (\"No Record returned / Record Key  \\n\")\n",
    "        \n",
    "    t0 = datetime.datetime.now()\n",
    "    \n",
    "    customers_response = featurestore_runtime.get_record(\n",
    "        FeatureGroupName=customers_fg_name, \n",
    "        RecordIdentifierValueAsString=str(sample_policy_id)\n",
    "    )\n",
    "    \n",
    "    t1 = datetime.datetime.now()\n",
    "\n",
    "    customer_record = customers_response['Record']\n",
    "    customer_df = pd.DataFrame(customer_record).set_index('FeatureName')\n",
    "    \n",
    "    \n",
    "    blended_df = pd.concat([claims_df, customer_df]).loc[col_order].drop('fraud')\n",
    " \n",
    "    data_input = ','.join(blended_df['ValueAsString'])\n",
    "  \n",
    "    results = predictor.predict(data_input, initial_args = {\"ContentType\": \"text/csv\"})\n",
    "    prediction = json.loads(results)\n",
    "    #print (f'Probablitity the claim from policy {int(sample_policy_id)} is fraudulent:', prediction)\n",
    "    \n",
    "    arr = t1-t0\n",
    "    minutes, seconds = divmod(arr.total_seconds(), 60)\n",
    "    \n",
    "    timer.append(seconds)\n",
    "    #print (prediction, \" done in {} \".format(seconds))\n",
    "    \n",
    "    return sample_policy_id, prediction\n",
    "\n",
    "\n",
    "for i in range(MAXRECS):\n",
    "    sample_policy_id, prediction = barrage_of_inference()\n",
    "    print (f'Probablitity the claim from policy {int(sample_policy_id)} is fraudulent:', prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.104207,\n",
       " 0.018295,\n",
       " 0.014252,\n",
       " 0.011944,\n",
       " 0.015995,\n",
       " 0.01254,\n",
       " 0.009096,\n",
       " 0.010931,\n",
       " 0.010299,\n",
       " 0.012489,\n",
       " 0.010017,\n",
       " 0.010691,\n",
       " 0.016407,\n",
       " 0.01604,\n",
       " 0.010104,\n",
       " 0.010288,\n",
       " 0.01099,\n",
       " 0.073499,\n",
       " 0.011214,\n",
       " 0.009789,\n",
       " 0.022679,\n",
       " 0.009756,\n",
       " 0.009275,\n",
       " 0.010286,\n",
       " 0.010218,\n",
       " 0.010905,\n",
       " 0.009978,\n",
       " 0.009428,\n",
       " 0.009458,\n",
       " 0.009365,\n",
       " 0.009597,\n",
       " 0.009151,\n",
       " 0.010745,\n",
       " 0.01041,\n",
       " 0.011591,\n",
       " 0.009813,\n",
       " 0.009907,\n",
       " 0.009681,\n",
       " 0.010297,\n",
       " 0.011101,\n",
       " 0.010455,\n",
       " 0.011621,\n",
       " 0.011608,\n",
       " 0.010553,\n",
       " 0.010857,\n",
       " 0.043866,\n",
       " 0.009531,\n",
       " 0.01037,\n",
       " 0.010339,\n",
       " 0.010937,\n",
       " 0.112788,\n",
       " 0.030294,\n",
       " 0.009193,\n",
       " 0.009383,\n",
       " 0.013487,\n",
       " 0.010252,\n",
       " 0.008825,\n",
       " 0.008874,\n",
       " 0.008569,\n",
       " 0.009125,\n",
       " 0.00927,\n",
       " 0.009258,\n",
       " 0.009154,\n",
       " 0.008994,\n",
       " 0.00834,\n",
       " 0.00882,\n",
       " 0.008757,\n",
       " 0.009768,\n",
       " 0.009057,\n",
       " 0.009745,\n",
       " 0.010577,\n",
       " 0.009996,\n",
       " 0.00988,\n",
       " 0.009487,\n",
       " 0.009822,\n",
       " 0.009681,\n",
       " 0.009552,\n",
       " 0.009941,\n",
       " 0.009132,\n",
       " 0.009548,\n",
       " 0.008689,\n",
       " 0.008667,\n",
       " 0.009177,\n",
       " 0.008748,\n",
       " 0.008397,\n",
       " 0.008947,\n",
       " 0.008421,\n",
       " 0.008453,\n",
       " 0.012942,\n",
       " 0.009208,\n",
       " 0.009653,\n",
       " 0.012933,\n",
       " 0.009217,\n",
       " 0.0085,\n",
       " 0.009257,\n",
       " 0.008883,\n",
       " 0.011084,\n",
       " 0.008612,\n",
       " 0.008725,\n",
       " 0.147717]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: 위의 \"timer\"는 첫 번째 통화를 기록한 다음 온라인 피쳐 저장소에 대한 후속 호출을 기록합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p95: 0.03097259999999996, p99: 0.11313729000000017, mean: 0.014886640000000005 for 100 distinct feature store gets\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "import numpy as np\n",
    "statistics.mean(timer)  \n",
    "\n",
    "\n",
    "arr = np.array(timer)\n",
    "print(\"p95: {}, p99: {}, mean: {} for {} distinct feature store gets\".format(np.percentile(arr,95),np.percentile(arr,99),np.mean(arr), MAXRECS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull customer data from Customers feature group\n",
    "\n",
    "고객이 즉각적인 승인을 위해 온라인으로 보험 청구를 제출하면, 보험 회사는 온라인 피쳐 저장소에서 고객별 데이터를 가져와 모델 예측을 위한 입력으로 청구 데이터에 추가해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_response = featurestore_runtime.get_record(\n",
    "    FeatureGroupName=customers_fg_name, \n",
    "    RecordIdentifierValueAsString=str(sample_policy_id))\n",
    "\n",
    "customer_record = customers_response['Record']\n",
    "customer_df = pd.DataFrame(customer_record).set_index('FeatureName')\n",
    "\n",
    "\n",
    "claims_response = featurestore_runtime.get_record(\n",
    "    FeatureGroupName=claims_fg_name, \n",
    "    RecordIdentifierValueAsString=str(sample_policy_id))\n",
    "\n",
    "claims_record = claims_response['Record']\n",
    "claims_df = pd.DataFrame(claims_record).set_index('FeatureName')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format the datapoint\n",
    "\n",
    "데이터 포인트는 모델이 훈련되었을 때, 모든 피쳐가 올바른 순서로 된 정확한 입력 형식과 일치해야 합니다. 이 예에서 `col_order` 변수는 가이드의 앞부분에서 훈련 및 테스트 데이터셋을 만들 때 저장되었습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended_df = pd.concat([claims_df, customer_df]).loc[col_order].drop('fraud')\n",
    "data_input = ','.join(blended_df['ValueAsString'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probablitity the claim from policy 3602 is fraudulent: 0.3037422001361847\n"
     ]
    }
   ],
   "source": [
    "results = predictor.predict(data_input, initial_args = {\"ContentType\": \"text/csv\"})\n",
    "prediction = json.loads(results)\n",
    "print (f'Probablitity the claim from policy {int(sample_policy_id)} is fraudulent:', prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a id='aud-workflow-pipeline'></a>\n",
    "### Next Notebook: [Create and Run an End-to-End Pipeline to Deploy the Model](./5-pipeline-e2e.ipynb)\n",
    "\n",
    "이제 데이터 과학자로서 머신 러닝 워크플로의 각 단계를 수동으로 실험했으므로, 모델 계보를 통한 투명성 및 추적을 희생하지 않고도 더 빠른 모델 생성 및 배포를 허용하는 특정 단계를 수행할 수 있습니다. 다음 섹션에서는 SageMaker에서 새 모델을 훈련하고 SageMaker에서 모델을 유지한 다음, 모델을 레지스트리에 추가하고 SageMaker 호스팅 엔드 포인트로 배포하는 파이프라인을 생성합니다."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
