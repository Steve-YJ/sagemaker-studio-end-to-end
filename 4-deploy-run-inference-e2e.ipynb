{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 : Deploy, Run Inference, Interpret Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='overview-4'></a>\n",
    "\n",
    "## [Overview](./0-AutoClaimFraudDetection.ipynb)\n",
    "* [Notebook 0 : Overview, Architecture and Data Exploration](./0-AutoClaimFraudDetection.ipynb)\n",
    "* [Notebook 1: Data Prep, Process, Store Features](./1-data-prep-e2e.ipynb)\n",
    "* [Notebook 2: Train, Check Bias, Tune, Record Lineage, and Register a Model](./2-lineage-train-assess-bias-tune-registry-e2e.ipynb)\n",
    "* [Notebook 3: Mitigate Bias, Train New Model, Store in Registry](./3-mitigate-bias-train-model2-registry-e2e.ipynb)\n",
    "* **[Notebook 4: Deploy Model, Run Predictions](./4-deploy-run-inference-e2e.ipynb)**\n",
    "  * **[Architecture](#deploy)**\n",
    "  * **[Deploy an approved model and Run Inference via Feature Store](#deploy-model)**\n",
    "  * **[Create a Predictor](#predictor)**\n",
    "  * **[Run Predictions from Online FeatureStore](#run-predictions)**\n",
    "* [Notebook 5 : Create and Run an End-to-End Pipeline to Deploy the Model](./5-pipeline-e2e.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End-to-end 유즈케이스를 다루는 이 섹션에서는, 사기 탐지 사용 사례의 최종 프로덕션인 mmitigated 모델을 배포합니다. 추론을 실행하는 방법과 Clarify를 사용하여 모델을 해석하거나 \"설명\"하는 방법을 보여줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required and/or update third-party libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install -Uq pip\n",
    "!python -m pip install -q awswrangler==2.2.0 imbalanced-learn==0.7.0 sagemaker==2.23.1 boto3==1.16.48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load stored variables\n",
    "\n",
    "이전에 이 노트북을 실행한 경우, AWS에서 생성한 리소스를 재사용할 수 있습니다. 아래 셀을 실행하여 이전에 생성된 변수를 로드합니다. 기존 변수의 출력물이 표시되어야 합니다. 인쇄된 내용이 보이지 않으면 노트북을 처음 실행한 것일 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "bucket                          -> 'sagemaker-us-east-1-143656149352'\n",
      "claims_fg_name                  -> 'fraud-detect-demo-claims'\n",
      "claims_table                    -> 'fraud-detect-demo-claims-1616324730'\n",
      "col_order                       -> ['fraud', 'policy_state_az', 'policy_annual_premiu\n",
      "customers_fg_name               -> 'fraud-detect-demo-customers'\n",
      "customers_table                 -> 'fraud-detect-demo-customers-1616324731'\n",
      "database_name                   -> 'sagemaker_featurestore'\n",
      "hyperparameters                 -> {'max_depth': '3', 'eta': '0.2', 'objective': 'bin\n",
      "model_1_name                    -> 'fraud-detect-demo-xgboost-pre-smote'\n",
      "model_2_name                    -> 'fraud-detect-demo-xgboost-post-smote'\n",
      "model_data                      -> 's3://sagemaker-us-east-1-143656149352/pytorch-smd\n",
      "mp2_arn                         -> 'arn:aws:sagemaker:us-east-1:143656149352:model-pa\n",
      "mpg_name                        -> 'fraud-detect-demo'\n",
      "prefix                          -> 'fraud-detect-demo'\n",
      "test_data_uri                   -> 's3://sagemaker-us-east-1-143656149352/fraud-detec\n",
      "train_data_uri                  -> 's3://sagemaker-us-east-1-143656149352/fraud-detec\n",
      "training_job_1_name             -> 'sagemaker-xgboost-2021-03-21-11-18-45-847'\n",
      "training_job_2_name             -> 'sagemaker-xgboost-2021-03-21-11-39-34-183'\n"
     ]
    }
   ],
   "source": [
    "%store -r\n",
    "%store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Important</font>: StoreMagic 명령을 사용하여 변수를 검색하려면 이전 노트북을 실행해야 합니다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import boto3\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import awswrangler as wr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set region, boto3 and SageMaker SDK variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using AWS Region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "#You can change this to a region of your choice\n",
    "import sagemaker\n",
    "region = sagemaker.Session().boto_region_name\n",
    "print(\"Using AWS Region: {}\".format(region))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.setup_default_session(region_name=region)\n",
    "\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "s3_client = boto3.client('s3', region_name=region)\n",
    "\n",
    "sagemaker_boto_client = boto_session.client('sagemaker')\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_boto_client)\n",
    "\n",
    "sagemaker_role = sagemaker.get_execution_role()\n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity()[\"Account\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables used for parameterizing the notebook run\n",
    "endpoint_name = f'{model_2_name}-endpoint'\n",
    "endpoint_instance_count = 1\n",
    "endpoint_instance_type = \"ml.m4.xlarge\"\n",
    "\n",
    "predictor_instance_count = 1\n",
    "predictor_instance_type = \"ml.c5.xlarge\"\n",
    "batch_transform_instance_count = 1\n",
    "batch_transform_instance_type = \"ml.c5.xlarge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id ='deploy'> </a>\n",
    "## Architecture for this ML Lifecycle Stage : Train, Check Bias, Tune, Record Lineage, Register Model\n",
    "[overview](#overview-4)\n",
    "\n",
    "![train-assess-tune-register](./images/e2e-3-pipeline-v3b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id ='deploy-model'></a>\n",
    "\n",
    "## Deploy an approved model and make prediction via Feature Store\n",
    "\n",
    "[overview](#overview-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approve the second model\n",
    "\n",
    "실제 MLOps 라이프사이클에서 모델 패키지는 데이터 과학자, 주제 전문가 및 감사자가 평가한 후 승인됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_model_package = sagemaker_boto_client.list_model_packages(ModelPackageGroupName=mpg_name)['ModelPackageSummaryList'][0]\n",
    "model_package_update = {\n",
    "    'ModelPackageArn': second_model_package['ModelPackageArn'],\n",
    "    'ModelApprovalStatus': 'Approved'\n",
    "}\n",
    "\n",
    "update_response = sagemaker_boto_client.update_model_package(**model_package_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an endpoint config and an endpoint\n",
    "엔드포인트를 배포합니다. 약 8분 정도 걸릴 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'endpoint_config_name' (str)\n"
     ]
    }
   ],
   "source": [
    "primary_container = {'ModelPackageName': second_model_package['ModelPackageArn']}\n",
    "endpoint_config_name=f'{model_2_name}-endpoint-config'\n",
    "existing_configs = len(sagemaker_boto_client.list_endpoint_configs(NameContains=endpoint_config_name, MaxResults = 30)['EndpointConfigs'])\n",
    "\n",
    "if existing_configs == 0:\n",
    "    create_ep_config_response = sagemaker_boto_client.create_endpoint_config(\n",
    "        EndpointConfigName=endpoint_config_name,\n",
    "        ProductionVariants=[{\n",
    "            'InstanceType': endpoint_instance_type,\n",
    "            'InitialVariantWeight': 1,\n",
    "            'InitialInstanceCount': endpoint_instance_count,\n",
    "            'ModelName': model_2_name,\n",
    "            'VariantName': 'AllTraffic'\n",
    "        }]\n",
    "    )\n",
    "    %store endpoint_config_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'endpoint_name' (str)\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: InService\n"
     ]
    }
   ],
   "source": [
    "existing_endpoints = sagemaker_boto_client.list_endpoints(NameContains=endpoint_name, MaxResults = 30)['Endpoints']\n",
    "if not existing_endpoints:\n",
    "    create_endpoint_response = sagemaker_boto_client.create_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        EndpointConfigName=endpoint_config_name)\n",
    "    %store endpoint_name\n",
    "\n",
    "endpoint_info = sagemaker_boto_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "endpoint_status = endpoint_info['EndpointStatus']\n",
    "\n",
    "while endpoint_status == 'Creating':\n",
    "    endpoint_info = sagemaker_boto_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    endpoint_status = endpoint_info['EndpointStatus']\n",
    "    print('Endpoint status:', endpoint_status)\n",
    "    if endpoint_status == 'Creating':\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='predictor'> </a>\n",
    "\n",
    "### Create a predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = sagemaker.predictor.Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample a claim from the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/dataset.csv')\n",
    "train = dataset.sample(frac=0.8, random_state=0)\n",
    "test = dataset.drop(train.index)\n",
    "sample_policy_id  = int(test.sample(1)['policy_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 0 to 4997\n",
      "Data columns (total 48 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Unnamed: 0                       1000 non-null   int64  \n",
      " 1   policy_id                        1000 non-null   int64  \n",
      " 2   policy_state_az                  1000 non-null   int64  \n",
      " 3   policy_annual_premium            1000 non-null   int64  \n",
      " 4   total_claim_amount               1000 non-null   float64\n",
      " 5   collision_type_side              1000 non-null   int64  \n",
      " 6   auto_year                        1000 non-null   int64  \n",
      " 7   num_insurers_past_5_years        1000 non-null   int64  \n",
      " 8   incident_type_theft              1000 non-null   int64  \n",
      " 9   collision_type_front             1000 non-null   int64  \n",
      " 10  policy_state_ca                  1000 non-null   int64  \n",
      " 11  num_injuries                     1000 non-null   int64  \n",
      " 12  fraud                            1000 non-null   int64  \n",
      " 13  driver_relationship_self         1000 non-null   int64  \n",
      " 14  driver_relationship_other        1000 non-null   int64  \n",
      " 15  incident_dow                     1000 non-null   int64  \n",
      " 16  policy_liability                 1000 non-null   int64  \n",
      " 17  driver_relationship_spouse       1000 non-null   int64  \n",
      " 18  incident_day                     1000 non-null   int64  \n",
      " 19  policy_state_wa                  1000 non-null   int64  \n",
      " 20  policy_state_nv                  1000 non-null   int64  \n",
      " 21  authorities_contacted_none       1000 non-null   int64  \n",
      " 22  months_as_customer               1000 non-null   int64  \n",
      " 23  policy_state_id                  1000 non-null   int64  \n",
      " 24  customer_education               1000 non-null   int64  \n",
      " 25  collision_type_na                1000 non-null   int64  \n",
      " 26  policy_deductable                1000 non-null   int64  \n",
      " 27  authorities_contacted_police     1000 non-null   int64  \n",
      " 28  vehicle_claim                    1000 non-null   float64\n",
      " 29  authorities_contacted_ambulance  1000 non-null   int64  \n",
      " 30  incident_type_breakin            1000 non-null   int64  \n",
      " 31  num_claims_past_year             1000 non-null   int64  \n",
      " 32  customer_age                     1000 non-null   int64  \n",
      " 33  incident_month                   1000 non-null   int64  \n",
      " 34  customer_gender_female           1000 non-null   int64  \n",
      " 35  injury_claim                     1000 non-null   float64\n",
      " 36  driver_relationship_na           1000 non-null   int64  \n",
      " 37  police_report_available          1000 non-null   int64  \n",
      " 38  collision_type_rear              1000 non-null   int64  \n",
      " 39  driver_relationship_child        1000 non-null   int64  \n",
      " 40  incident_severity                1000 non-null   int64  \n",
      " 41  incident_type_collision          1000 non-null   int64  \n",
      " 42  customer_gender_male             1000 non-null   int64  \n",
      " 43  num_witnesses                    1000 non-null   int64  \n",
      " 44  num_vehicles_involved            1000 non-null   int64  \n",
      " 45  authorities_contacted_fire       1000 non-null   int64  \n",
      " 46  policy_state_or                  1000 non-null   int64  \n",
      " 47  incident_hour                    1000 non-null   int64  \n",
      "dtypes: float64(3), int64(45)\n",
      "memory usage: 382.8 KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get sample's claim data from online feature store\n",
    "\n",
    "아래 코드 셀은 고객의 보험 청구 제출에서 실시간으로 데이터를 가져 오는 것을 시뮬레이션합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurestore_runtime = boto_session.client(service_name='sagemaker-featurestore-runtime', region_name=region)\n",
    "\n",
    "feature_store_session = sagemaker.Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_boto_client,\n",
    "    sagemaker_featurestore_runtime_client=featurestore_runtime\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='run-predictions'> </a>\n",
    "## Run Predictions on Multiple Claims\n",
    "\n",
    "[overview](#overview-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probablitity the claim from policy 97 is fraudulent: 0.040728937834501266\n",
      "Probablitity the claim from policy 3671 is fraudulent: 0.0453115738928318\n",
      "Probablitity the claim from policy 4972 is fraudulent: 0.040728937834501266\n",
      "Probablitity the claim from policy 1182 is fraudulent: 0.04572128504514694\n",
      "Probablitity the claim from policy 633 is fraudulent: 0.01687716506421566\n",
      "Probablitity the claim from policy 1394 is fraudulent: 0.021264027804136276\n",
      "Probablitity the claim from policy 585 is fraudulent: 0.040728937834501266\n",
      "Probablitity the claim from policy 2329 is fraudulent: 0.040728937834501266\n",
      "Probablitity the claim from policy 4907 is fraudulent: 0.027355268597602844\n",
      "Probablitity the claim from policy 1189 is fraudulent: 0.07697506248950958\n",
      "Probablitity the claim from policy 4737 is fraudulent: 0.01687716506421566\n",
      "Probablitity the claim from policy 1243 is fraudulent: 0.040728937834501266\n",
      "Probablitity the claim from policy 2562 is fraudulent: 0.2340942919254303\n",
      "Probablitity the claim from policy 297 is fraudulent: 0.040728937834501266\n",
      "Probablitity the claim from policy 4548 is fraudulent: 0.023151209577918053\n",
      "Probablitity the claim from policy 1515 is fraudulent: 0.01687716506421566\n",
      "Probablitity the claim from policy 888 is fraudulent: 0.07722954452037811\n",
      "Probablitity the claim from policy 760 is fraudulent: 0.040728937834501266\n",
      "Probablitity the claim from policy 2690 is fraudulent: 0.040728937834501266\n",
      "Probablitity the claim from policy 129 is fraudulent: 0.040728937834501266\n",
      "Probablitity the claim from policy 184 is fraudulent: 0.0453115738928318\n",
      "Probablitity the claim from policy 3016 is fraudulent: 0.040728937834501266\n",
      "Probablitity the claim from policy 2640 is fraudulent: 0.022258823737502098\n",
      "Probablitity the claim from policy 3051 is fraudulent: 0.021264027804136276\n",
      "Probablitity the claim from policy 4127 is fraudulent: 0.033001165837049484\n",
      "Probablitity the claim from policy 2705 is fraudulent: 0.07943026721477509\n",
      "Probablitity the claim from policy 4478 is fraudulent: 0.040728937834501266\n",
      "Probablitity the claim from policy 3638 is fraudulent: 0.01687716506421566\n",
      "Probablitity the claim from policy 3933 is fraudulent: 0.040728937834501266\n",
      "Probablitity the claim from policy 1338 is fraudulent: 0.01687716506421566\n",
      "Probablitity the claim from policy 4459 is fraudulent: 0.03122321516275406\n",
      "Probablitity the claim from policy 21 is fraudulent: 0.030335986986756325\n",
      "Probablitity the claim from policy 3045 is fraudulent: 0.04390726983547211\n",
      "Probablitity the claim from policy 4609 is fraudulent: 0.022258823737502098\n",
      "Probablitity the claim from policy 56 is fraudulent: 0.033179983496665955\n",
      "Probablitity the claim from policy 1395 is fraudulent: 0.01687716506421566\n",
      "Probablitity the claim from policy 4904 is fraudulent: 0.040050603449344635\n",
      "Probablitity the claim from policy 2823 is fraudulent: 0.040728937834501266\n",
      "Probablitity the claim from policy 887 is fraudulent: 0.01687716506421566\n",
      "Probablitity the claim from policy 4910 is fraudulent: 0.030335986986756325\n",
      "Probablitity the claim from policy 3671 is fraudulent: 0.0453115738928318\n",
      "Probablitity the claim from policy 3638 is fraudulent: 0.01687716506421566\n",
      "Probablitity the claim from policy 4287 is fraudulent: 0.08855964988470078\n",
      "Probablitity the claim from policy 4972 is fraudulent: 0.040728937834501266\n",
      "Probablitity the claim from policy 56 is fraudulent: 0.033179983496665955\n",
      "Probablitity the claim from policy 339 is fraudulent: 0.01687716506421566\n",
      "Probablitity the claim from policy 4872 is fraudulent: 0.01687716506421566\n",
      "Probablitity the claim from policy 4525 is fraudulent: 0.040728937834501266\n",
      "Probablitity the claim from policy 1348 is fraudulent: 0.01687716506421566\n",
      "Probablitity the claim from policy 1791 is fraudulent: 0.038223106414079666\n",
      "Probablitity the claim from policy 3962 is fraudulent: 0.033001165837049484\n",
      "Probablitity the claim from policy 335 is fraudulent: 0.03379044681787491\n",
      "Probablitity the claim from policy 3271 is fraudulent: 0.033001165837049484\n",
      "Probablitity the claim from policy 4143 is fraudulent: 0.040728937834501266\n",
      "Probablitity the claim from policy 1242 is fraudulent: 0.1210184246301651\n",
      "Probablitity the claim from policy 4295 is fraudulent: 0.0507810115814209\n",
      "Probablitity the claim from policy 913 is fraudulent: 0.01687716506421566\n",
      "Probablitity the claim from policy 3730 is fraudulent: 0.01687716506421566\n",
      "Probablitity the claim from policy 3298 is fraudulent: 0.01687716506421566\n",
      "Probablitity the claim from policy 3280 is fraudulent: 0.02717301808297634\n",
      "Probablitity the claim from policy 899 is fraudulent: 0.03122321516275406\n",
      "Probablitity the claim from policy 4380 is fraudulent: 0.023151209577918053\n",
      "Probablitity the claim from policy 4872 is fraudulent: 0.01687716506421566\n",
      "Probablitity the claim from policy 3537 is fraudulent: 0.03122321516275406\n",
      "Probablitity the claim from policy 4817 is fraudulent: 0.021043647080659866\n",
      "Probablitity the claim from policy 2462 is fraudulent: 0.01687716506421566\n",
      "Probablitity the claim from policy 887 is fraudulent: 0.01687716506421566\n",
      "Probablitity the claim from policy 4447 is fraudulent: 0.040050603449344635\n",
      "Probablitity the claim from policy 2856 is fraudulent: 0.08723791688680649\n",
      "Probablitity the claim from policy 2476 is fraudulent: 0.06716256588697433\n",
      "Probablitity the claim from policy 1985 is fraudulent: 0.033001165837049484\n",
      "Probablitity the claim from policy 258 is fraudulent: 0.08723791688680649\n",
      "Probablitity the claim from policy 1242 is fraudulent: 0.1210184246301651\n",
      "Probablitity the claim from policy 2844 is fraudulent: 0.040728937834501266\n",
      "Probablitity the claim from policy 2677 is fraudulent: 0.1237938180565834\n",
      "Probablitity the claim from policy 826 is fraudulent: 0.12330227345228195\n",
      "Probablitity the claim from policy 71 is fraudulent: 0.040728937834501266\n",
      "Probablitity the claim from policy 4324 is fraudulent: 0.033001165837049484\n",
      "Probablitity the claim from policy 3973 is fraudulent: 0.021264027804136276\n",
      "Probablitity the claim from policy 1338 is fraudulent: 0.01687716506421566\n",
      "Probablitity the claim from policy 4561 is fraudulent: 0.033001165837049484\n",
      "Probablitity the claim from policy 265 is fraudulent: 0.01687716506421566\n",
      "Probablitity the claim from policy 2141 is fraudulent: 0.10204272717237473\n",
      "Probablitity the claim from policy 2482 is fraudulent: 0.05797983705997467\n",
      "Probablitity the claim from policy 1964 is fraudulent: 0.040728937834501266\n",
      "Probablitity the claim from policy 2012 is fraudulent: 0.08472588658332825\n",
      "Probablitity the claim from policy 2559 is fraudulent: 0.03606869652867317\n",
      "Probablitity the claim from policy 1748 is fraudulent: 0.01687716506421566\n",
      "Probablitity the claim from policy 369 is fraudulent: 0.021264027804136276\n",
      "Probablitity the claim from policy 1287 is fraudulent: 0.01687716506421566\n",
      "Probablitity the claim from policy 188 is fraudulent: 0.040728937834501266\n",
      "Probablitity the claim from policy 1985 is fraudulent: 0.033001165837049484\n",
      "Probablitity the claim from policy 1671 is fraudulent: 0.021264027804136276\n",
      "Probablitity the claim from policy 4561 is fraudulent: 0.033001165837049484\n",
      "Probablitity the claim from policy 4163 is fraudulent: 0.023705093190073967\n",
      "Probablitity the claim from policy 3003 is fraudulent: 0.06741451472043991\n",
      "Probablitity the claim from policy 4242 is fraudulent: 0.01687716506421566\n",
      "Probablitity the claim from policy 4355 is fraudulent: 0.01687716506421566\n",
      "Probablitity the claim from policy 3902 is fraudulent: 0.028626710176467896\n",
      "Probablitity the claim from policy 1676 is fraudulent: 0.033001165837049484\n"
     ]
    }
   ],
   "source": [
    "import datetime  as datetime\n",
    "timer =[]\n",
    "MAXRECS = 100\n",
    "\n",
    "def barrage_of_inference():\n",
    "    sample_policy_id  = int(test.sample(1)['policy_id'])\n",
    "    \n",
    "    temp_fg_name = 'fraud-detect-demo-claims'\n",
    "\n",
    "    claims_response = featurestore_runtime.get_record(\n",
    "        FeatureGroupName=temp_fg_name, \n",
    "        RecordIdentifierValueAsString= str(sample_policy_id)\n",
    "\n",
    "    )\n",
    "\n",
    "    if (claims_response.get('Record')):\n",
    "        claims_record = claims_response['Record']\n",
    "        claims_df = pd.DataFrame(claims_record).set_index('FeatureName')\n",
    "    else:\n",
    "        print (\"No Record returned / Record Key  \\n\")\n",
    "        \n",
    "    t0 = datetime.datetime.now()\n",
    "    \n",
    "    customers_response = featurestore_runtime.get_record(\n",
    "        FeatureGroupName=customers_fg_name, \n",
    "        RecordIdentifierValueAsString=str(sample_policy_id)\n",
    "    )\n",
    "    \n",
    "    t1 = datetime.datetime.now()\n",
    "\n",
    "    customer_record = customers_response['Record']\n",
    "    customer_df = pd.DataFrame(customer_record).set_index('FeatureName')\n",
    "    \n",
    "    \n",
    "    blended_df = pd.concat([claims_df, customer_df]).loc[col_order].drop('fraud')\n",
    "    data_input = ','.join(blended_df['ValueAsString'])\n",
    "    \n",
    "    results = predictor.predict(data_input, initial_args = {\"ContentType\": \"text/csv\"})\n",
    "    prediction = json.loads(results)\n",
    "    #print (f'Probablitity the claim from policy {int(sample_policy_id)} is fraudulent:', prediction)\n",
    "    \n",
    "    arr = t1-t0\n",
    "    minutes, seconds = divmod(arr.total_seconds(), 60)\n",
    "    \n",
    "    timer.append(seconds)\n",
    "    #print (prediction, \" done in {} \".format(seconds))\n",
    "    \n",
    "    return sample_policy_id, prediction\n",
    "\n",
    "\n",
    "for i in range(MAXRECS):\n",
    "    sample_policy_id, prediction = barrage_of_inference()\n",
    "    print (f'Probablitity the claim from policy {int(sample_policy_id)} is fraudulent:', prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.091086,\n",
       " 0.009347,\n",
       " 0.012332,\n",
       " 0.0092,\n",
       " 0.009026,\n",
       " 0.008019,\n",
       " 0.008513,\n",
       " 0.00787,\n",
       " 0.008133,\n",
       " 0.008389,\n",
       " 0.007583,\n",
       " 0.008283,\n",
       " 0.008953,\n",
       " 0.012898,\n",
       " 0.008464,\n",
       " 0.008109,\n",
       " 0.008112,\n",
       " 0.008467,\n",
       " 0.008234,\n",
       " 0.007799,\n",
       " 0.00755,\n",
       " 0.007967,\n",
       " 0.008053,\n",
       " 0.008424,\n",
       " 0.007892,\n",
       " 0.007571,\n",
       " 0.007794,\n",
       " 0.007625,\n",
       " 0.007456,\n",
       " 0.008095,\n",
       " 0.007985,\n",
       " 0.007782,\n",
       " 0.046095,\n",
       " 0.007993,\n",
       " 0.008344,\n",
       " 0.007812,\n",
       " 0.007602,\n",
       " 0.008101,\n",
       " 0.007838,\n",
       " 0.008206,\n",
       " 0.008851,\n",
       " 0.007558,\n",
       " 0.007864,\n",
       " 0.008814,\n",
       " 0.007575,\n",
       " 0.008173,\n",
       " 0.008939,\n",
       " 0.007797,\n",
       " 0.007881,\n",
       " 0.008265,\n",
       " 0.103398,\n",
       " 0.008466,\n",
       " 0.010886,\n",
       " 0.007812,\n",
       " 0.00816,\n",
       " 0.008833,\n",
       " 0.008626,\n",
       " 0.008736,\n",
       " 0.007807,\n",
       " 0.008693,\n",
       " 0.008476,\n",
       " 0.008497,\n",
       " 0.009165,\n",
       " 0.007975,\n",
       " 0.007418,\n",
       " 0.008082,\n",
       " 0.007874,\n",
       " 0.008178,\n",
       " 0.0083,\n",
       " 0.010709,\n",
       " 0.008418,\n",
       " 0.008163,\n",
       " 0.009192,\n",
       " 0.009038,\n",
       " 0.008279,\n",
       " 0.008787,\n",
       " 0.012666,\n",
       " 0.008325,\n",
       " 0.00736,\n",
       " 0.008555,\n",
       " 0.0076,\n",
       " 0.008674,\n",
       " 0.008137,\n",
       " 0.00752,\n",
       " 0.007469,\n",
       " 0.0083,\n",
       " 0.007149,\n",
       " 0.007314,\n",
       " 0.007656,\n",
       " 0.007525,\n",
       " 0.008445,\n",
       " 0.009669,\n",
       " 0.007625,\n",
       " 0.00756,\n",
       " 0.008108,\n",
       " 0.011109,\n",
       " 0.007855,\n",
       " 0.008482,\n",
       " 0.008399,\n",
       " 0.008019]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: 위의 \"timer\"는 첫 번째 통화를 기록한 다음 온라인 피쳐 저장소에 대한 후속 호출을 기록합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p95: 0.012348699999999997, p99: 0.09120912000000006, mean: 0.01054208 for 100 distinct feature store gets\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "import numpy as np\n",
    "statistics.mean(timer)  \n",
    "\n",
    "\n",
    "arr = np.array(timer)\n",
    "print(\"p95: {}, p99: {}, mean: {} for {} distinct feature store gets\".format(np.percentile(arr,95),np.percentile(arr,99),np.mean(arr), MAXRECS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull customer data from Customers feature group\n",
    "\n",
    "고객이 즉각적인 승인을 위해 온라인으로 보험 청구를 제출하면, 보험 회사는 온라인 피쳐 저장소에서 고객별 데이터를 가져와 모델 예측을 위한 입력으로 청구 데이터에 추가해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_response = featurestore_runtime.get_record(\n",
    "    FeatureGroupName=customers_fg_name, \n",
    "    RecordIdentifierValueAsString=str(sample_policy_id))\n",
    "\n",
    "customer_record = customers_response['Record']\n",
    "customer_df = pd.DataFrame(customer_record).set_index('FeatureName')\n",
    "\n",
    "\n",
    "claims_response = featurestore_runtime.get_record(\n",
    "    FeatureGroupName=claims_fg_name, \n",
    "    RecordIdentifierValueAsString=str(sample_policy_id))\n",
    "\n",
    "claims_record = claims_response['Record']\n",
    "claims_df = pd.DataFrame(claims_record).set_index('FeatureName')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format the datapoint\n",
    "\n",
    "데이터 포인트는 모델이 훈련되었을 때, 모든 피쳐가 올바른 순서로 된 정확한 입력 형식과 일치해야 합니다. 이 예에서 `col_order` 변수는 가이드의 앞부분에서 훈련 및 테스트 데이터셋을 만들 때 저장되었습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended_df = pd.concat([claims_df, customer_df]).loc[col_order].drop('fraud')\n",
    "data_input = ','.join(blended_df['ValueAsString'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probablitity the claim from policy 1676 is fraudulent: 0.033001165837049484\n"
     ]
    }
   ],
   "source": [
    "results = predictor.predict(data_input, initial_args = {\"ContentType\": \"text/csv\"})\n",
    "prediction = json.loads(results)\n",
    "print (f'Probablitity the claim from policy {int(sample_policy_id)} is fraudulent:', prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a id='aud-workflow-pipeline'></a>\n",
    "### Next Notebook: [Create and Run an End-to-End Pipeline to Deploy the Model](./5-pipeline-e2e.ipynb)\n",
    "\n",
    "이제 데이터 과학자로서 머신 러닝 워크플로의 각 단계를 수동으로 실험했으므로, 모델 계보를 통한 투명성 및 추적을 희생하지 않고도 더 빠른 모델 생성 및 배포를 허용하는 특정 단계를 수행할 수 있습니다. 다음 섹션에서는 SageMaker에서 새 모델을 훈련하고 SageMaker에서 모델을 유지한 다음, 모델을 레지스트리에 추가하고 SageMaker 호스팅 엔드 포인트로 배포하는 파이프라인을 생성합니다."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
